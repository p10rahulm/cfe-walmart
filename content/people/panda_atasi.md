+++
name = "Atasi Panda"
person_role = "PhD Fellow"
person_designation = "PhD Fellow, IISc, Bangalore"
person_link = ""
person_photofile = "assets/images/people_images/atasipanda.jpg"
notes = ""
+++

Atasi is a PhD candidate in the Department of Computer Science and Automation at the Indian Institute of Science (IISc), Bengaluru, under Prof. Anand Louis. Before this, she worked as a Software Developer at Uber, San Francisco, after completing her masterâ€™s in computer science at the University of Wisconsin, Madison.

<br><br><b>Research Interests</b>
<br>
Her current research work broadly focuses on fairness in algorithms.

<b>Impact.<b> Algorithms and machine learning models helping many critical industries (banking, renting, etc.) in decision making, and the realization that there could be an inherent bias in data, leading to marginalization of demographic groups, has led to the pertinent strive for fairness in algorithmic design. Due to the potential amplification of bias through automation in decision-making involving people, demographic disparities and an adverse impact on individuals have been extensively studied. To mitigate such biases, the importance of group fairness and individual constraints has been repeatedly stressed in literature. With the rise of social networks and knowledge graphs, graph-structured data and graph algorithms are now widely used in many tasks like search and recommendation. Therefore, addressing fairness in graph problems is beyond debatable. Fairness in graph-cuts can be used to model and address fair disaster management. Bipartite matching finds applications in real-world scenarios, such as ad auctions, resource allocation, school choice, healthcare rationing, recommendation systems, paper bidding, etc. Therefore, our work on fairness under the different settings of the bipartite matching problem could lead to more equitable solutions.

